{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset Classification Model Training\n",
    "# This notebook was generated to train a MobileNetV2 model on your dataset.\n",
    "# Follow the steps below to upload the dataset and run the training.\n",
    "\n",
    "# Step 1: Upload the dataset zip file\n",
    "from google.colab import files\n",
    "print(\"Please upload your dataset zip file (archive 2.zip):\")\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 2: Extract the uploaded zip file\n",
    "dataset_dir = '/content/dataset'\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "zip_path = '/content/archive 2.zip'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_dir)\n",
    "\n",
    "# Clean up zip file\n",
    "os.remove(zip_path)\n",
    "\n",
    "# Step 3: Detect classes and organize dataset into train and validation directories\n",
    "base_dir = dataset_dir  # Assume dataset is extracted directly into dataset_dir\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "# Detect class directories\n",
    "classes = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Create train and validation directories\n",
    "if not os.path.exists(train_dir):\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(train_dir, cls))\n",
    "        os.makedirs(os.path.join(val_dir, cls))\n",
    "\n",
    "    # Split images: 80% train, 20% validation\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(base_dir, cls)\n",
    "        images = [f for f in os.listdir(cls_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(images)\n",
    "        train_size = int(0.8 * len(images))\n",
    "\n",
    "        for img in images[:train_size]:\n",
    "            shutil.move(os.path.join(cls_dir, img), os.path.join(train_dir, cls, img))\n",
    "        for img in images[train_size:]:\n",
    "            shutil.move(os.path.join(cls_dir, img), os.path.join(val_dir, cls, img))\n",
    "\n",
    "# Step 4: Load and preprocess the dataset\n",
    "IMG_SIZE = 224  # MobileNetV2 expects 224x224 images\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Step 5: Build the CNN model using MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 6: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Ensure accuracy is at least 90%\n",
    "if val_accuracy >= 0.90:\n",
    "    print(\"Achieved at least 90% accuracy!\")\n",
    "else:\n",
    "    print(\"Accuracy below 90%. Consider fine-tuning MobileNetV2 or increasing epochs.\")\n",
    "\n",
    "# Step 9: Save the model\n",
    "model.save('/content/dataset_classification_cnn.h5')\n",
    "print(\"Model saved as '/content/dataset_classification_cnn.h5'\")\n",
    "\n",
    "# Optional: Save to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "shutil.copy('/content/dataset_classification_cnn.h5', '/content/drive/MyDrive/dataset_classification_cnn.h5')\n",
    "print(\"Model copied to Google Drive at '/content/drive/MyDrive/dataset_classification_cnn.h5'\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
